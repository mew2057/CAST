{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark, RERUN EVERY TIME!\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "\n",
    "conf = SparkConf()\\\n",
    "        .setMaster(\"local\")\\\n",
    "        .setAppName(\"Sandbox\")\n",
    "\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index Constants\n",
    "TRANS_ALLOC = \"cast-allocation-ornl\"\n",
    "TRANS_STEP  = \"cast-allocation-step-ornl\"\n",
    "STEP_HIST   = \"cast-db-csm_step_history-ornl-*\"\n",
    "NODE_HIST   = \"cast-db-csm_allocation_node_history-ornl-*\"\n",
    "ALLOC_HIST  = \"cast-db-csm_allocation_history-ornl-*\"\n",
    "\n",
    "# Set the Connection Constants\n",
    "NODES       = \"10.7.4.15,10.7.4.17\"\n",
    "PORTS       = \"9200\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Node  History\n",
    "\n",
    "We want to get some data from the allocation node history table before anything else and leverage Elasticsearch. Step 1 is to determine which fields we want and how we're going to aggregate them (tons of data is great, but skew can be just as if not more interesting) Using this we can start to refine the allocation data to make it easier to run analytics on the allocation data. The following variables are all in the **data** object. The data will be condensed to pivot on the **data.allocation_id**. \n",
    "\n",
    "**NOTE:** This is one way of analyzing the data. Other analytics may be written using the raw allocation node data, but I'm interested in a few specific indicators to apply to the overall allocation.\n",
    "\n",
    "* **memory_usage_max**\n",
    "    * Should store the Average and the Maximum values.\n",
    "    * **mem_usage_avg**\n",
    "    * **mem_usage_max**\n",
    "* **gpu_usage**\n",
    "    * Trickier, do we want the total sum or average of all nodes?\n",
    "    * **gpu_usage_avg**\n",
    "* **gpfs_read**\n",
    "    * I think the average across all nodes should be appropriate to get a sense for GPFS usage in general.\n",
    "    * **gpfs_read_avg**\n",
    "* **gpfs_write**\n",
    "    * I think the average across all nodes should be appropriate to get a sense for GPFS usage in general.\n",
    "    * **gpfs_write_avg**\n",
    "* **allocation_id**\n",
    "    * Pivot value, summations and math operations pivot on this data point.\n",
    "* **cpu_usage**\n",
    "    * Average should be fine, can show trends. If combined with median, could indicate uneven workload.\n",
    "    * **cpu_usage_avg**\n",
    "    * **cpu_usage_median**\n",
    "* **ib_tx**\n",
    "    * **ib_tx_avg** \n",
    "* **ib_rx**\n",
    "    * **ib_rx_avg** \n",
    "* **energy**\n",
    "    * **energy_avg**\n",
    "    * **energy_median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('oCdm_WkBkJgQNSr8xBAB',\n",
       " {'data': {'memory_usage_max': 11143151616,\n",
       "   'gpu_usage': 0,\n",
       "   'gpfs_write': 0,\n",
       "   'gpu_energy': 57513,\n",
       "   'allocation_id': 142879,\n",
       "   'ib_rx': 1518456391,\n",
       "   'gpfs_read': 13189120,\n",
       "   'cpu_usage': 208634895474,\n",
       "   'ib_tx': 1516901943,\n",
       "   'energy': 134047}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's Write a Query!\n",
    "\n",
    "NHistQuery = '''\n",
    "{ \n",
    "    \"query\" : {\n",
    "        \"match_all\" : {} \n",
    "    }\n",
    "}'''\n",
    "\n",
    "NHistFields = [\"data.allocation_id\", \"data.ib_tx\", \"data.ib_rx\", \"data.memory_usage_max\", \"data.gpu_usage\",\n",
    "                \"data.gpfs_read\", \"data.gpfs_write\", \"data.gpu_energy\", \"data.cpu_usage\", \"data.energy\"]\n",
    "\n",
    "es_conf = {\"es.resource\": \"{0}\".format(NODE_HIST),\n",
    "          \"es.nodes\"    : NODES,\n",
    "          \"es.port\"     : PORTS,\n",
    "          \"es.query\"    : NHistQuery, \n",
    "          \"es.read.field.include\" : \",\".join(NHistFields) }\n",
    "\n",
    "nodeHist = sc.newAPIHadoopRDD(\"org.elasticsearch.hadoop.mr.EsInputFormat\",\\\n",
    "                         \"org.apache.hadoop.io.NullWritable\", \\\n",
    "                         \"org.elasticsearch.hadoop.mr.LinkedMapWritable\",conf=es_conf)\n",
    "\n",
    "\n",
    "nodeHist.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "\n",
    "nHHistReduced = nodeHist.reduceByKey(add)\n",
    "\n",
    "#\"es.read.field.include\" : NHistFields'\n",
    "\n",
    "nHHistReduced.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodeHist.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
